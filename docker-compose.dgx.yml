# DGX Spark 專用 Docker Compose (ARM64 + Blackwell GB10)
# 針對 NVIDIA Grace Blackwell 架構優化
# 參考：https://github.com/Mekopa/whisperx-blackwell
#
# 首次建置需要較長時間（~30分鐘），因為需要從源碼編譯：
# - torchaudio v2.6.0
# - CTranslate2 v4.4.0

services:
  # === Redis ===
  redis:
    image: redis:7-alpine
    container_name: whisper-redis-dgx
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # === API 服務 ===
  whisper-api:
    build:
      context: .
      dockerfile: Dockerfile.dgx
    container_name: whisper-api-dgx
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Blackwell GPU 相容性
      - TORCH_CUDA_ARCH_LIST=9.0
      - CUDA_FORCE_PTX_JIT=1
      - HF_TOKEN=${HF_TOKEN}
      - MODEL_SIZE=${MODEL_SIZE:-large-v3}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-float16}
      - BATCH_SIZE=${BATCH_SIZE:-16}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - TORCH_FORCE_WEIGHTS_ONLY_LOAD=0
    volumes:
      - ./cache/huggingface:/root/.cache/huggingface
      - ./cache/torch:/root/.cache/torch
      - ./cache/app:/app/cache
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped
    # DGX Spark GPU 配置
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu, compute, utility]
              count: all

  # === Celery Worker ===
  whisper-worker:
    build:
      context: .
      dockerfile: Dockerfile.dgx
    container_name: whisper-worker-dgx
    command: celery -A workers.celery_app worker --loglevel=info -Q transcription,default -c 2
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Blackwell GPU 相容性
      - TORCH_CUDA_ARCH_LIST=9.0
      - CUDA_FORCE_PTX_JIT=1
      - CELERY_WORKER_ID=0
      - HF_TOKEN=${HF_TOKEN}
      - MODEL_SIZE=${MODEL_SIZE:-large-v3}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-float16}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - TORCH_FORCE_WEIGHTS_ONLY_LOAD=0
    volumes:
      - ./cache/huggingface:/root/.cache/huggingface
      - ./cache/torch:/root/.cache/torch
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu, compute, utility]
              count: all

volumes:
  redis_data:

networks:
  default:
    name: whisper-network-dgx
